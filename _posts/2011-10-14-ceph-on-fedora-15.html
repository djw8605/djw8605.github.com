---
title: CEPH on Fedora 15
date: '2011-10-14T11:14:00.000-05:00'
author: Derek Weitzel
tags:
- ceph
- osg
- Cluster
modified_time: '2012-02-17T20:30:31.745-06:00'
blogger_id: tag:blogger.com,1999:blog-3007054864987759910.post-5695847306491579
blogger_orig_url: http://derekweitzel.blogspot.com/2011/10/ceph-on-fedora-15.html
---

Yesterday, I read a <a href="http://berrange.com/posts/2011/10/12/setting-up-a-ceph-cluster-and-exporting-a-rbd-volume-to-a-kvm-guest/">blog post</a>&nbsp;using <a href="http://ceph.newdream.net/">CEPH</a> for a backend store for virtual machine images. &nbsp;I've heard a lot about ceph in the last year, especially after it was integrated into the mainline kernel in 2.6.34. &nbsp;So I thought I'd give it a try.<br /><br />Before I get into the install, I want to summarize my thoughts on Ceph. &nbsp;I think it has a lot of potential, but parts of it are trying too hard to do everything for you. &nbsp;I always think there is a careful balance between a program doing too much for you, and making you do too much. &nbsp;For example, the mkcephfs script that creates a ceph filesystem will ssh to all the worker nodes (defined in ceph.conf) and configure the filesystem. &nbsp;If I was in operations, this would scare me.<br /><br />Also, the keychain configuration is overly complicated. &nbsp;I think the Ceph is designed to be secure over the WAN (secure, not encrypted), so maybe it's needed. &nbsp;But it seems overly complicated when you compare it to other distributed file systems (Hadoop, Lustre).<br /><br />On the other hand, I really like the full posix compliant client, especially since it's in the mainline kernel. &nbsp;It is too bad that it was added in 2.6.34 rather than 2.6.32 (RHEL 6 kernel). &nbsp;I guess we'll have to wait 2 years for RHEL 7 to have it in something we can use in production.<br /><br />Also, the distributed metadata and multiple metadata servers are interesting aspects to the system. &nbsp;Though, in the version I tested, the MDS crashed a few times (the system picked it up and compensated).<br /><br />On Fedora 15, ceph packages are in the repos.<br /><pre>yum install ceph</pre><br />The configuration I settled on was:<br /><pre>[global]<br />    auth supported = cephx<br />    keyring = /etc/ceph/keyring.admin<br /><br />[mds]<br />    keyring = /etc/ceph/keyring.$name<br />[mds.i-00000072]<br />    host = i-00000072<br />[mds.i-00000073]<br />    host = i-00000073<br />[mds.i-00000074]<br />    host = i-00000074<br /><br />[osd]<br />    osd data = /srv/ceph/osd$id<br />    osd journal = /srv/ceph/osd$id/journal<br />    osd journal size = 512<br />    osd class dir = /usr/lib64/rados-classes<br />    keyring = /etc/ceph/keyring.$name<br />[osd0]<br />    host = i-00000072<br />[osd1]<br />    host = i-00000073<br />[osd2]<br />    host = i-00000074<br /><br />[mon]<br />    mon data = /srv/ceph/mon$id<br />[mon0]<br />    host = i-00000072<br />    mon addr = 10.148.2.147:6789<br />[mon1]<br />    host = i-00000073<br />    mon addr = 10.148.2.148:6789<br />[mon2]<br />    host = i-00000074<br />    mon addr = 10.148.2.149:6789</pre><br />As you can read from the configuration file, all files are stored in /srv/ceph/... &nbsp;You will need to make this directory on all your worker nodes.<br /><br />Next I needed to create a keyring for&nbsp;authentication&nbsp;with the client/admin/dataservers. &nbsp;The keyring tool is distributed with Ceph, and is called&nbsp;<a href="http://manpages.ubuntu.com/manpages/maverick/man8/cauthtool.8.html">cauthtool</a>. &nbsp;Even now, it's not clear to me how to use this tool, or how Ceph uses the keyring. &nbsp;First you need to make a caps (capabilities?) file:<br /><br /><pre>osd = "allow *"<br />mds = "allow *"<br />mon = "allow *"<br /></pre><br />Here are the cauthtool commands to get it to work.<br /><br /><pre>cauthtool --create-keyring /etc/ceph/keyring.bin<br />cauthtool -c -n i-00000072 --gen-key /etc/ceph/keyring.bin <br />cauthtool -n i-00000074 --caps caps /etc/ceph/keyring.bin<br />cauthtool -c -n i-00000073 --gen-key /etc/ceph/keyring.bin<br />cauthtool -n i-00000073 --caps caps /etc/ceph/keyring.bin<br />cauthtool -c -n i-00000074 --gen-key /etc/ceph/keyring.bin <br />cauthtool -n i-00000072 --caps caps /etc/ceph/keyring.bin<br />cauthtool --gen-key --name=admin /etc/ceph/keyring.admin<br /></pre><br /><br />From the blog post linked above, I used their script to create the directories and copy the ceph.conf to the other hosts.<br /><br /><pre>n=0<br />for host in i-00000072 i-00000073 i-00000074 ; \<br />   do \<br />       ssh root@$host mkdir -p /etc/ceph /srv/ceph/mon$n; \<br />       n=$(expr $n + 1); \<br />       scp /etc/ceph/ceph.conf root@$host:/etc/ceph/ceph.conf<br />   done<br />mkcephfs -a -c /etc/ceph/ceph.conf -k /etc/ceph/keyring.bin<br /></pre><br /><br />Then copy the keyrings<br /><pre>for host in i-00000072 i-00000073 i-00000074 ; \<br />   do \<br />       scp /etc/ceph/keyring.admin root@$host:/etc/ceph/keyring.admin; \<br />   done<br /></pre><br /><br />Then startup the daemons on all the nodes:<br /><br /><pre>service ceph start</pre><br />And to mount the system:<br /><pre>mount -t ceph 10.148.2.147:/ /mnt/ceph -o name=admin,secret=AQBlV5dO2TICABAA0/FP7m+ru6TJLZaPxFuQyg==</pre><br />Where the secret is the output from the command:<br /><pre> cauthtool --print-key /etc/ceph/keyring.bin </pre><br />
