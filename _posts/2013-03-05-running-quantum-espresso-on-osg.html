---
title: Running Quantum Espresso on the OSG
date: '2013-03-05T12:53:00.000-06:00'
author: Derek Weitzel
tags:
- osg
- condor
modified_time: '2013-03-05T15:47:55.830-06:00'
blogger_id: tag:blogger.com,1999:blog-3007054864987759910.post-2337400839561942722
blogger_orig_url: http://derekweitzel.blogspot.com/2013/03/running-quantum-espresso-on-osg.html
---

While running Quantum Espresso on the Open Science Grid, we found a number of issues:<br /><ul><li>OpenMPI needs to have an rsh binary. &nbsp;Even if you are using shared memory for openmpi, and openmpi does not use rsh, it still looks for the binary and fails if it cannot find it.</li><li>Chroots (used on HCC machines for grid jobs) do not support pty's. &nbsp;OpenMPI has a compile option to turn off pty support.</li></ul><div>Once these issues where fixed, we were able to submit QE jobs to the OSG using Condor's partitionable slots on 8 cores.</div><div><br /></div><h3>Preparing Submission</h3><div>Before submitting our first QE job, we had to compile OpenMPI and QE. &nbsp;Since we are an HPC center, we had OpenMPI compiled for our Infiniband, therefore it would always fail on the OSG where there is no Infiniband (let alone our brand and drivers).</div><div><br /></div><div>After compiling, we created compressed files that contained the required files to run QE:</div><div><ul><li>bin.tar.gz - Only includes the cp.x file, specific to our run. &nbsp;It could have well included much more common pw.x.</li><li>lib.tar.gz - Includes the Intel math libraries and libgfortran.</li><li>openmpi.tar.gz - Includes the entire openmpi install directory (make install)</li></ul></div><div>Additionally, we wrote a wrapper script, run_espresso_grid.sh, that unpacks the required files and sets the environment.<br /><br /><div class="gistLoad" data-id="5093020" id="gist-5093020"><pre>#!/bin/bash<br />tar xzf bin.tar.gz<br />tar xzf lib.tar.gz<br />tar xzf pseudo.tar.gz<br />tar xzf openmpi.tar.gz<br />mkdir tmp<br /> <br />export PATH=$PWD/bin:$PWD/openmpi/bin:$PATH<br />export LD_LIBRARY_PATH=$PWD/lib:$PWD/openmpi/lib:$LD_LIBRARY_PATH<br />export OPAL_PREFIX=$PWD/openmpi<br /> <br />mpirun --mca orte_rsh_agent `pwd`/rsh -np 8 cp.x &lt; h2o-64-grid.in &gt; h2o-64-grid.out<br /></pre></div><h3>Submission</h3></div><div>We used GlideinWMS to submit to the OSG, below is our HTCondor submit file.</div><div><div class="gistLoad" data-id="5092949" id="gist-5092949"><pre>universe = vanilla<br />output = condor.out.$(CLUSTER).$(PROCESS)<br />error = condor.err.$(CLUSTER).$(PROCESS)<br />log            = condor.log<br />executable = run_espresso_grid.sh<br />request_cpus=8<br />request_memory = 10*1024<br />should_transfer_files = YES<br />when_to_transfer_output = ON_EXIT_OR_EVICT<br />transfer_input_files = bin.tar.gz, lib.tar.gz, pseudo.tar.gz, openmpi.tar.gz, h2o-64-grid.in, /usr/bin/rsh<br />transfer_output_files =h2o-64-grid.out<br />+RequiresWholeMachine=True<br />Requirements = CAN_RUN_WHOLE_MACHINE =?= TRUE<br />queue <br /></pre></div><br /></div><div>Note that we pull rsh from the submission machine. &nbsp;OpenMPI does not actually use rsh to start the processes on a shared memory machine, but it does require that the RSH binary is available.<br /><br /></div><div><h3>Acknowledgments</h3></div><div>This was done with the tremendous help of Jun Wang.</div><div><br /></div><script src="https://raw.github.com/moski/gist-Blogger/master/public/gistLoader.js" type="text/javascript"></script> <br /><center><br /><a href="http://creativecommons.org/licenses/by/3.0/deed.en_US" rel="license"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by/3.0/88x31.png" style="border-width: 0;" /></a><br />This work is licensed under a <a href="http://creativecommons.org/licenses/by/3.0/deed.en_US" rel="license">Creative Commons Attribution 3.0 Unported License</a>. </center>
